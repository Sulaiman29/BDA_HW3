{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sulaiman29/BDA_HW3/blob/main/Copy_of_BDA2025Spring_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR3tA_mpMLTq"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\"><b></b>\n",
        "<h1><center> <font color='black'> Homework 03</font></center></h1>\n",
        "<h2><center> <font color='black'> Classification & Evaluation</font></center></h2>    \n",
        "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
        "<h2><center> <font color='black'> University of Tartu - Spring 2025</font></center></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVDAIuJlMLUI"
      },
      "source": [
        "# Homework instructions\n",
        "\n",
        "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID.\n",
        "\n",
        "- Please provide code where ever applicable.\n",
        "\n",
        "- The accepted submission format is .ipynb file. If you are sharing Colab link, make sure that the privacy settings for the file is public so we can access your code.\n",
        "\n",
        "- The submission will automatically close on <font color='red'>**20 April at 23:59**</font>, so please make sure to submit before the deadline.\n",
        "\n",
        "- ONLY one of the teammates should submit the homework and in the submission description the other person's Name and Student ID must be entered. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
        "\n",
        "- If a question is not clear, please ask us in Moodle ONLY.\n",
        "\n",
        "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues.\n",
        "\n",
        "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://ut.ee/en/content/academic-fraud).\n",
        "\n",
        "- <font color='red'>**DO NOT CHANGE THE TEMPLATE**</font>\n",
        "\n",
        "- <font color='red'>**Restart the Kernel and Run all the cells once again after you are done.**</font>\n",
        "This will ensure that all the cells run without error. You will find an option in the top menu bar under Kernel tab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajm9qYjsMLUU"
      },
      "source": [
        "**<h2><font color='red'>Team mates:</font></h2>**\n",
        "\n",
        "\n",
        "<font color='red'>Name: </font>&emsp;   <font color='red'>Student ID: </font>\n",
        "\n",
        "\n",
        "<font color='red'>Name: </font>&emsp;   <font color='red'>Student ID: </font>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSA889NUZs_U"
      },
      "source": [
        "### The homework is divided into four sections and the points are distributed as below:\n",
        "<pre>\n",
        "- Classification tasks       -> 9.5 points\n",
        "- Improving classification   -> 2.5 points\n",
        "__________________________________________\n",
        "Total                        -> 12 points\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3vqLGBCMLUh"
      },
      "source": [
        "# 1. Classification tasks (9.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq8fuNbAMLUs"
      },
      "source": [
        "We are going to use the dataset from the file HR_Employee_Attrition.csv which contains data about the employees of a company and the fact if they have left the company due to reasons like retirement, resignation, elimination of a position, personal health, etc. It is important for companies to predict if their employees are going to leave because the hiring process is costly and requires planification. The data has the following columns:\n",
        "\n",
        "\n",
        "Age – self descriptive\n",
        "\n",
        "BusinessTravel – how frequent employee travels\n",
        "\n",
        "DailyRate – daily rate on terms of salary\n",
        "\n",
        "Department – self descriptive\n",
        "\n",
        "DistanceFromHome – distance between employee home and work\n",
        "\n",
        "Education – education level of employee\n",
        "\n",
        "EducationField – self descriptive\n",
        "\n",
        "EnvironmentSatisfaction – level of satisfaction with working environment\n",
        "\n",
        "Gender – self descriptive\n",
        "\n",
        "HourlyRate – self descriptive\n",
        "\n",
        "JobRole – self descriptive\n",
        "\n",
        "JobInvolvement – level of interest of the job\n",
        "\n",
        "JobSatisfaction – level of satisfaction with current job\n",
        "\n",
        "MaritalStatus – self descriptive\n",
        "\n",
        "MonthlyIncome – self descriptive\n",
        "\n",
        "MonthlyRate – self descriptive\n",
        "\n",
        "NumCompaniesWorked – self descriptive\n",
        "\n",
        "Over18 – whether customer age is more than 18\n",
        "\n",
        "OverTime – whether customer works overtime or not\n",
        "\n",
        "PerformanceRating – performance level of employee\n",
        "\n",
        "RelationshipSatisfaction – level of satisfaction with working community\n",
        "\n",
        "StandardHours – standard amount of hours that employee works\n",
        "\n",
        "TotalWorkingYears – Amount of working years\n",
        "\n",
        "TrainingTimesLastYear – How many times did employee get training over the last year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjr3pwZCMLU6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUsbyScxMLVd"
      },
      "source": [
        "hr_data = pd.read_csv('HR_Employee_Attrition.csv', header=0)\n",
        "hr_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is8x9Ju4MLWJ"
      },
      "source": [
        "## 1.1 Dataset exploration (1.7 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJiBjvKEMLWV"
      },
      "source": [
        "**1.1.0.\n",
        "Plot the correlation of the variables against ```Attrition```. (0.5 points)<br>Make sure you perform necessary preprocessing required for the plot.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S0dw0W7MLWd",
        "scrolled": false
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "d4rv0AJiSvmA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdQNOhknMLWv"
      },
      "source": [
        "**1.1.1. Write three interesting observation that you notice. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAR1gdyRSvE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIubn6J7MLW6"
      },
      "source": [
        "**<font color='red'>Answer 1:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1qgfB9UbbvC"
      },
      "source": [
        "**<font color='red'>Answer 2:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQfSuYJGbdL0"
      },
      "source": [
        "**<font color='red'>Answer 3:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-Hxf9mdMLXZ"
      },
      "source": [
        "**1.1.2 Plot a boxplot for ```TotalWorkingYears``` for both Attrition categories. Explain the result. (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDoUwZs4MLXk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRG9mu7EZs_Y"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jFZYAmkMLX3"
      },
      "source": [
        "**1.1.3. Plot the relative frequency of Attrition values (Yes/No)  (0.3 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj7FAx2oMLYA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "ZbC19Q5sSuMf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeHvmFAvMLYk"
      },
      "source": [
        "## 1.2 Classification  (7.8 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYU-BjCIMLYv"
      },
      "source": [
        "**1.2.1 We will predict the variable ```Attrition``` by applying different classification algorithms and compare them. But before that we have to split the data into training and test set. And before splitting the dataset, please perform the following preprocessing. (0.5 points)**\n",
        "* One hot encoding (You probably performed this in ```1.1.0```, in case if you have not)\n",
        "* Drop three columns with least correlation values. (Use the plot from ```1.1.0```)\n",
        "* Be a vigilante, and look for columns that has suspicious values. Drop those columns (at least 2 columns), it will not be much of a help in classification.\n",
        "* Finally normalize the training variables, use the following Z-Score normalizing equation for normalization; <br>\n",
        "\n",
        "$$x_{norm}= \\frac{x -\\mu}{\\sigma}.$$ <br>\n",
        "\n",
        "Here, $\\mu$ = mean of the training variables, $\\sigma$ = standard deviation of the training variables. <br>\n",
        "\n",
        "What is **Z-score**: It is a a scaling method that represents the number of standard deviations away from the mean. You would use z-score to ensure your feature distributions have mean = 0 and std = 1. It’s useful when there are a few outliers, but not so extreme that you need clipping. Clipping is another technique when you clip off (remove) outliers by visualizing the distribution of your dataset [1]. the following figure shows how Z-score impacts the values, notice the x-axis for both the figures.\n",
        "<img src=\"https://developers.google.com/static/machine-learning/data-prep/images/norm-z-score.svg\" alt=\"img\" border=\"0\"></a><br />\n",
        "Ref: https://developers.google.com/machine-learning/data-prep/transform/normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sjN8R1YMLY8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#TODO: one hot encoding\n",
        "\n",
        "#TODO: drop three columns with least correlation\n",
        "\n",
        "#TODO: drop suspicious columns (there should be at least two)\n",
        "\n",
        "#TODO: normalization\n",
        "\n",
        "#TODO: split the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "KzsSkNQjStIt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFrtucYjMLZy"
      },
      "source": [
        "**1.2.2 Use the scikit-learn DecisionTreeClassifier with default parameters to predict the attrition value for the test set. Set the random seed to 0. Calculate the accuracy score and print it. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ytUenLMLZ5"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier as DT\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "model = DT(random_state=0)\n",
        "#TODO: train the model\n",
        "#TODO: predict on test set\n",
        "#TODO: print accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "6fUcNpAfSsTU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFj7-9m-MLaF"
      },
      "source": [
        "**1.2.3 Plot the confusion matrix for the predicted values. Why accuracy is not a good metric to use in this case ? (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJOLZ7JJMLaN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3nN1_M3Zs_d"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_DZJ_vlMLap"
      },
      "source": [
        "**1.2.4 Formulate a dummy model (not a machine learning approach) to get atleast 80% accuracy. Considering the label ratios how this model would look like? Be creative. You do not require to code for this, just a simple assumption and mathematical proof is necessary. (0.5 points)** <br>\n",
        "Hint: There are two labels (yes, no) in your data."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2tvAbXFSqDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov12wEZWMLat"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCogwmH-MLay"
      },
      "source": [
        "**1.2.5 Use export_graphviz from sklearn.tree to visualize the trained decision tree of ```1.2.2```. (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0rwCCqDMLa7",
        "scrolled": false
      },
      "source": [
        "#!pip3 install graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "ATq4AODBSq0R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWX-1InxMLbU"
      },
      "source": [
        "**1.2.6 Look at the visualization, what is the most important factor to decide if an employee is going to leave or not? (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mwt0Sc4MLbc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEFpbEYHMLb2"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Puw9lIlbMLb9"
      },
      "source": [
        "\n",
        "**1.2.7 Plot the classification report for the same decision tree. Which evaluation metrics out of precision and recall, would you consider for this specific case-study? Please elaborate your answer. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfQz4VSNMLcH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4QrRGORMLci"
      },
      "source": [
        "**<font color='red'>Answer:</font>**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cyKqrkDMLcs"
      },
      "source": [
        "**1.2.8 Calculate the F1 score of the model in training data and compare it with the F1 score in test  data. What is the phenomenon known as? (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnx2h53qMLc1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2WYaL4kMLdU"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRsrRj76CjjB"
      },
      "source": [
        "**1.2.9 Use cross validation score to ensure that our model is generalizing well. Try different combinations of maximum depth parameters for the decision tree and choose the best while using cross validation. Please complete the code below and report the best maximum depth. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8jBr23zDzMn"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "best_score = 0\n",
        "best_depth = 0\n",
        "\n",
        "for i in range(#Low_range,#high_range):\n",
        "    clf = DT(max_depth=i, random_state = 0)\n",
        "    #TODO: Perform 5-fold cross validation.\n",
        "    #set scoring metrics to f1\n",
        "    scores = #TODO: initialization\n",
        "\n",
        "    #TODO: calculate the mean score (f1)\n",
        "\n",
        "    #TODO: compare the mea scores to find the best depth\n",
        "    print('Mean score', mean_score)\n",
        "\n",
        "print('\\n The best tree depth is: ', best_depth )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "rZEZOAoASm-c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFTtDD7GMLda"
      },
      "source": [
        "**1.2.10 Use SVM with default parameters to classify test data and report accuracy, recall, precision, f1-score and AUC. Set the random_state equal to 0. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w23rLdVpMLd7"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_model = SVC(random_state=0)\n",
        "\n",
        "#TODO: train the model\n",
        "#TODO: predict on test set\n",
        "#TODO: calculate the metrics\n",
        "\n",
        "print('Accuracy: ', acc)\n",
        "print('Recall: ', rec)\n",
        "print('Precision: ', prec)\n",
        "print('F1_score: ', f1_score)\n",
        "print('AUC: ', auc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "yIiM3c0hSmgY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3NxlOM0MLeL"
      },
      "source": [
        "**1.2.11 Use Logistic Regression with default parameters to classify test data and report accuracy, recall, precision, f1-score, AUC. Set the random_state equal to 0 (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg2_nAivMLeT"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(random_state=0)\n",
        "\n",
        "#TODO: train the model\n",
        "#TODO: predict on test set\n",
        "#TODO: calculate the metrics\n",
        "\n",
        "print('Accuracy: ', acc)\n",
        "print('Recall: ', rec)\n",
        "print('Precision: ', prec)\n",
        "print('F1_score: ', f1_score)\n",
        "print('AUC: ', auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "CiJOvkBySl6G"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouBtSaYTJBcL"
      },
      "source": [
        "**1.2.12 One of the parameters for the Logistic regression is tol which sets the tolerance for the stopping criteria. We are going to calculate the log loss metric for different values of tol. Please fill in the code below and plot the log loss values. Which one of tol values is better for our model based on log loss? (0.5 points)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQpm6s2SJxJG"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "log_loss = []\n",
        "for tol in [0.9, 0.5, 0.1,  0.001, 0.0001, 0.000001, 0.000001]:\n",
        "\n",
        "    #TODO: initialize the model\n",
        "    #TODO: train the models\n",
        "    #TODO: predict on test set\n",
        "    #TODO: calculate logloss\n",
        "    #TODO: use log_loss list to store the different logloss for different tol\n",
        "\n",
        "tol = [0.9, 0.5, 0.1,  0.001, 0.0001, 0.000001, 0.000001]\n",
        "plt.plot(tol, log_loss)\n",
        "plt.ylabel(\"Log Loss\")\n",
        "plt.xlabel(\"tol\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Findidng out the best tolerance value\n",
        "min_index=(log_loss.index(min(log_loss)))\n",
        "print(\"Best Tolerance, tol, Value: \", tol[min_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "F98OPIlNSlSZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2z05iMlMLep"
      },
      "source": [
        "**1.2.13 Use Random Forest with default parameters to classify test data and report accuracy, recall, precision and f1-score and AUC. Set the random_state equal to 0. Please build as well a classification report separately which shows the metrics for each class. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWibHlLAMLew"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=0)\n",
        "\n",
        "#TODO: train the model\n",
        "#TODO: predict on test set\n",
        "#TODO: classification report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "3-LVRuesSksI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJrqNiijMfjW"
      },
      "source": [
        "**1.2.14 Use the model from ```1.2.13```, calculate the predicted probability on test set. Threshold the probabilities such that it will output the class 'No'  only if the probability is 70% or higher. Otherwise, it will predict 'Yes'. (0.3 points)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GpWHAWvNWZL"
      },
      "source": [
        "#TODO: predict probability on test set\n",
        "#TODO: threshold probability\n",
        "\n",
        "y_pred_threshold = ... #use this variable to store value\n",
        "\n",
        "print(y_pred_threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "Isb-bVMYSkCN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk80i4XKNX6W"
      },
      "source": [
        "**1.2.15 Print the classification report again. Do you think there were some improvements regarding the classification for class Yes? Explain your answer briefly. (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C48fb3jNW4d"
      },
      "source": [
        "#TODO: Print classification report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am9hDnA5OMX6"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nge1WamEMLfJ"
      },
      "source": [
        "**1.2.16 Use XGBoost with default parameters to classify test data and report accuracy, recall, precision, f1-score and AUC. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO5l5l03MLfO"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier()\n",
        "\n",
        "#TODO: train the model\n",
        "#TODO: predict on test set\n",
        "#TODO: calculate the metrics\n",
        "\n",
        "print('Accuracy: ', acc)\n",
        "print('Recall: ', rec)\n",
        "print('Precision: ', prec)\n",
        "print('F1_score: ', f1_score)\n",
        "print('AUC: ', auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "GFZCB3I2Siv2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W41zIM_iMLfo"
      },
      "source": [
        "**1.2.17 For unbalanced datasets, choose the best classifier (based on evaluation metrics that seems good for this case-study) and plot its feature importances in decreasing order. Were the 3 most important features as you expected, you can use ```1.2.5``` as reference? Please explain why. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNhXkEyhZs_j"
      },
      "source": [
        "#TODO: choose a model\n",
        "#TODO: train the model\n",
        "\n",
        "#TODO: predict on test set\n",
        "#TODO: calculate the metrics\n",
        "\n",
        "#TODO: feature importance calculation\n",
        "\n",
        "#TODO: plot the feature importance\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khLM_PzmMLfv"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GBmXXe8MLf2"
      },
      "source": [
        "# 2. Improving classification (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjqzAyR4MLgM"
      },
      "source": [
        "**2.1 Do you think it is better to try oversampling or downsampling in this case study and why ? (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zCiGsxCShFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDkfyTzhMLgR"
      },
      "source": [
        "**<font color='red'>Answer:</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaYBgnPLMLgY"
      },
      "source": [
        "**2.2 Apply oversampling to the data while keeping random_state equal to 0. (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj2QLJR8MLgn"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "#TODO: apply oversampling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "LElR-jcVSfsC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-bFmqpMLhP"
      },
      "source": [
        "**2.3 Split the data into train/test set with a ratio 80/20. Keep a random_state equal to 0. Train a random forest model, test it and report accuracy, precision, recall, f1-score and AUC. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQVlRIJvMLhX"
      },
      "source": [
        "#TODO: split dataset in 80/20 ratio. set random_state=0, use randomforest model\n",
        "#TODO: train a rf model on oversampled data\n",
        "#TODO: predict on test set\n",
        "#TODO: calculate metrics\n",
        "\n",
        "print('Accuracy: ', acc)\n",
        "print('Recall: ', rec)\n",
        "print('Precision: ', prec)\n",
        "print('F1_score: ', f1_score)\n",
        "print('AUC: ', auc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "Ip-KeNvqSex2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWxZ0WobMLhm"
      },
      "source": [
        "**2.4 Apply undersampling to the data while keeping random_state equal to 0. (0.4 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPIbRaRIMLhp"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "#TODO: apply undersampling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "CT72QsUWSeDZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsQzm2JmMLiC"
      },
      "source": [
        "**2.5 Split the data into train/test set with a ratio 80/20. Keep a random_state equal to 0. Train a random forest model, test it and report accuracy, precision, recall, f1-score and AUC. (0.5 points)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKi4p2MVMLiK"
      },
      "source": [
        "#TODO: split dataset in 80/20 ratio. set random_state=0, use randomforest model\n",
        "#TODO: train a rf model on undersampled data\n",
        "#TODO: predict on test set\n",
        "#TODO: calculate metrics\n",
        "\n",
        "print('Accuracy: ', acc)\n",
        "print('Recall: ', rec)\n",
        "print('Precision: ', prec)\n",
        "print('F1_score: ', f1_score)\n",
        "print('AUC: ', auc)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **Answer:**</font>"
      ],
      "metadata": {
        "id": "EuGyVTnLSdDr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUys5JOCZs_l"
      },
      "source": [
        "**2.6 Which one performed better between over and under sampling (0.3 points)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUz0sWNVSaN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn0V-iHeZs_l"
      },
      "source": [
        "<font color='red'> **Answer:**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on8nnIjpMLjE"
      },
      "source": [
        "## How long did it take you to solve the homework?\n",
        "\n",
        "* Please answer as precisely as you can. It does not affect your points or grade in any way. It is okay, if it took 0.5 hours or 24 hours. The collected information will be used to improve future homeworks.\n",
        "\n",
        "<font color='red'> **Answer:**</font>\n",
        "\n",
        "\n",
        "\n",
        "## What is the level of difficulty for this homework?\n",
        "you can put only number between $0:10$ ($0:$ easy, $10:$ difficult)\n",
        "\n",
        "<font color='red'> **Answer:** </font>\n",
        "\n",
        "## Any other comments regarding the homework?\n",
        "\n",
        "<font color='red'> **Answer:** </font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-SmcDvv-gHL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}